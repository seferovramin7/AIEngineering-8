{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e089f4ad",
   "metadata": {},
   "source": [
    "# Titanic Survival Analysis â€” Homework Project\n",
    "\n",
    "Author: Milzon  \n",
    "Dataset: Titanic (Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIEngineering-8\\Milzon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df985dd",
   "metadata": {},
   "source": [
    "# Titanic Survival Analysis - Step 1: Data Loading and Initial Exploration\n",
    "\n",
    "In this step, we load the Titanic dataset and perform initial data exploration to understand the data structure, missing values, and data types. This will help us decide on necessary cleaning and preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db721ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Caption:**  \n",
    "First five rows of the Titanic dataset. Let's explore the features and look for missing values or anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ad0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset (adjust path if needed)\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Show first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Show info summary including missing values\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138d30e",
   "metadata": {},
   "source": [
    "## Initial Data Exploration Insights\n",
    "\n",
    "- The dataset contains **891 passengers** with **12 columns** describing various features such as passenger ID, survival status, class, name, gender, age, family relations, ticket info, fare, cabin, and embarkation port.\n",
    "- There are **some missing values**, for example:\n",
    "  - `Cabin` has many missing entries (NaN).\n",
    "  - `Embarked` has a few missing values (889 non-null out of 891).\n",
    "- Data types vary:\n",
    "  - Numerical columns like `Age`, `Fare` are floats.\n",
    "  - Categorical columns like `Sex`, `Ticket`, `Cabin`, `Embarked` are objects (strings).\n",
    "- Age and Fare have decimal values, which suggests continuous variables.\n",
    "- The dataset appears well-structured and ready for initial cleaning and feature engineering.\n",
    "\n",
    "### Next steps based on this exploration:\n",
    "- Handle missing values, especially in `Age` and `Embarked`.\n",
    "- Consider encoding categorical features (`Sex`, `Embarked`, `Cabin`) to numeric for modeling.\n",
    "- Explore feature creation such as family size or title extraction from names.\n",
    "- Visualize distributions of key variables and survival rates to find patterns.\n",
    "\n",
    "---\n",
    "\n",
    "This initial exploration sets the foundation for effective preprocessing and model building.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae7d3c",
   "metadata": {},
   "source": [
    "## Task 1: Feature Detective \n",
    "\n",
    "Goal: Identify which features have the greatest impact on model accuracy by removing one feature at a time.\n",
    "\n",
    "Procedure:\n",
    "- Train a baseline model with all features.\n",
    "- Remove one feature (e.g., 'Sex', 'Pclass', 'Age', 'FamilySize') at a time.\n",
    "- Measure accuracy for each variation.\n",
    "- Compare accuracies to determine feature importance.\n",
    "\n",
    "Questions to answer:\n",
    "- Which feature removal hurt accuracy the most?\n",
    "- Which feature seems least important?\n",
    "- Why might 'Sex' or 'Pclass' be important for survival prediction?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3254b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy with all features: 0.8045\n",
      "Accuracy without Pclass: 0.7821\n",
      "Accuracy without Sex: 0.7542\n",
      "Accuracy without Age: 0.7877\n",
      "Accuracy without FamilySize: 0.8101\n",
      "\n",
      "Accuracy impact of removing each feature:\n",
      "Baseline (all features): 0.8045\n",
      "Without Pclass: 0.7821\n",
      "Without Sex: 0.7542\n",
      "Without Age: 0.7877\n",
      "Without FamilySize: 0.8101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preprocessing: example - create FamilySize\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Define features and target\n",
    "features = ['Pclass', 'Sex', 'Age', 'FamilySize']\n",
    "target = 'Survived'\n",
    "\n",
    "# Convert categorical feature 'Sex' to numeric\n",
    "df['Sex_numeric'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Prepare dataset function for modeling\n",
    "def prepare_data(feature_list):\n",
    "    X = df[feature_list].copy()\n",
    "    # Replace 'Sex' with 'Sex_numeric' if present\n",
    "    if 'Sex' in X.columns:\n",
    "        X['Sex'] = df['Sex_numeric']\n",
    "    # Fill missing age with median\n",
    "    if 'Age' in X.columns:\n",
    "        X['Age'] = X['Age'].fillna(df['Age'].median())\n",
    "    return X\n",
    "\n",
    "# Baseline model with all features\n",
    "X_all = prepare_data(features)\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "baseline_acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Baseline accuracy with all features: {baseline_acc:.4f}')\n",
    "\n",
    "# Test removing each feature\n",
    "results = {}\n",
    "for feature in features:\n",
    "    features_subset = [f for f in features if f != feature]\n",
    "    X_sub = prepare_data(features_subset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sub, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[feature] = acc\n",
    "    print(f'Accuracy without {feature}: {acc:.4f}')\n",
    "\n",
    "# Show comparison\n",
    "print(\"\\nAccuracy impact of removing each feature:\")\n",
    "print(f\"Baseline (all features): {baseline_acc:.4f}\")\n",
    "for feat, acc in results.items():\n",
    "    print(f\"Without {feat}: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
